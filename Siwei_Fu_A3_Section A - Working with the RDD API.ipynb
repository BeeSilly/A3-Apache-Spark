{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "structured-hearts",
   "metadata": {},
   "source": [
    "# Section A - Working with the RDD API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "through-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.113:7077\") \\\n",
    "        .appName(\"Siwei Fu A3 RDD\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-slave",
   "metadata": {},
   "source": [
    "## Question A.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "level-astrology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "['bg-en.en', 'cs-en.en', 'da-en.en', 'de-en.en', 'el-en.en', 'es-en.en', 'et-en.en', 'fi-en.en', 'fr-en.en', 'hu-en.en', 'it-en.en', 'lt-en.en', 'lv-en.en', 'nl-en.en', 'pl-en.en', 'pt-en.en', 'ro-en.en', 'sk-en.en', 'sl-en.en', 'sv-en.en']\n",
      "['bg-en.bg', 'cs-en.cs', 'da-en.da', 'de-en.de', 'el-en.el', 'es-en.es', 'et-en.et', 'fi-en.fi', 'fr-en.fr', 'hu-en.hu', 'it-en.it', 'lt-en.lt', 'lv-en.lv', 'nl-en.nl', 'pl-en.pl', 'pt-en.pt', 'ro-en.ro', 'sk-en.sk', 'sl-en.sl', 'sv-en.sv']\n"
     ]
    }
   ],
   "source": [
    "# The code in this bolock is to get the file list in the given folder\n",
    "# It is used to seperate the file of other language and it English transcript.\n",
    "# Referenced from https://stackoverflow.com/questions/35750614/pyspark-get-list-of-files-directories-on-hdfs-path\n",
    "\n",
    "URI           = spark_context._gateway.jvm.java.net.URI\n",
    "Path          = spark_context._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "FileSystem    = spark_context._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    "Configuration = spark_context._gateway.jvm.org.apache.hadoop.conf.Configuration\n",
    "\n",
    "fs = FileSystem.get(URI(\"hdfs://192.168.2.113:9000\"), Configuration())\n",
    "status = fs.listStatus(Path('/europarl/'))\n",
    "English_file = []\n",
    "Other_file = []\n",
    "for fileStatus in status:\n",
    "    temp = str(fileStatus.getPath())\n",
    "    if temp.endswith('.en'): # using the last 3 characters to distinguish the language file.\n",
    "        English_file.append(temp)\n",
    "    else:\n",
    "        Other_file.append(temp)\n",
    "        \n",
    "E_lines = spark_context.textFile(','.join(English_file))\n",
    "O_lines = spark_context.textFile(','.join(Other_file))\n",
    "\n",
    "print(len(English_file))\n",
    "print(len(Other_file))\n",
    "print([i.split('/')[-1].partition('.')[2] for i in English_file])\n",
    "print([i.split('/')[-1].partition('.')[2] for i in Other_file])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "serial-johnston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of lines for each language is the same? Anwser is: True.\n",
      "\n",
      "Total line from each file is [('bg-en', 406934, 406934), ('cs-en', 646605, 646605), ('da-en', 1968800, 1968800), ('de-en', 1920209, 1920209), ('el-en', 1235976, 1235976), ('es-en', 1965734, 1965734), ('et-en', 651746, 651746), ('fi-en', 1924942, 1924942), ('fr-en', 2007723, 2007723), ('hu-en', 624934, 624934), ('it-en', 1909115, 1909115), ('lt-en', 635146, 635146), ('lv-en', 637599, 637599), ('nl-en', 1997775, 1997775), ('pl-en', 632565, 632565), ('pt-en', 1960407, 1960407), ('ro-en', 399375, 399375), ('sk-en', 640715, 640715), ('sl-en', 623490, 623490), ('sv-en', 1862234, 1862234)].\n",
      "\n",
      "Total line from English transcripts is 24652024.\n",
      "Total line from transcripts in other languages is 24652024.\n",
      "The partition for finding out total line number for English is 38.\n",
      "The partition for finding out total line number for other languages is 40.\n"
     ]
    }
   ],
   "source": [
    "# A.1.1 Read the English transcripts with Spark, and count the number of lines.\n",
    "# A.1.2 Do the same with the other language (so that you have a separate lineage of RDDs for each).\n",
    "# A.1.3 Verify that the line counts are the same for the two languages.\n",
    "    # Anwser: Yes, the number of lines for each language file is the same,\n",
    "    #         and the total line number is also the same in 24652024.\n",
    "# A.1.4 Count the number of partitions.\n",
    "    # Anwser: The partitions for English file is 38, and for other languages is 40.\n",
    "\n",
    "line_num = []\n",
    "Flag = True\n",
    "\n",
    "for i in range(len(English_file)):\n",
    "    num_e = spark_context.textFile(English_file[i]).map(lambda i: 1).reduce(add)\n",
    "    num_o = spark_context.textFile(Other_file[i]).map(lambda i: 1).reduce(add)\n",
    "    line_num.append((Other_file[i][-2:]+'-en',num_e,num_o))\n",
    "    if num_e != num_o:\n",
    "        Flag = False\n",
    "        \n",
    "print(f\"The number of lines for each language is the same? Anwser is: {Flag}.\\n\")\n",
    "print(f\"Total line from each file is {line_num}.\\n\")\n",
    "\n",
    "etotal_lines = E_lines.map(lambda i: 1).reduce(add)\n",
    "ototal_lines = O_lines.map(lambda i: 1).reduce(add)\n",
    "\n",
    "print(f\"Total line from English transcripts is {etotal_lines}.\")\n",
    "print(f\"Total line from transcripts in other languages is {ototal_lines}.\")\n",
    "\n",
    "print(f'The partition for finding out total line number for English is {E_lines.getNumPartitions()}.')\n",
    "print(f'The partition for finding out total line number for other languages is {O_lines.getNumPartitions()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-peripheral",
   "metadata": {},
   "source": [
    "## Question A.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "framed-canyon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('membership of parliament: see minutes', ['membership', 'of', 'parliament:', 'see', 'minutes']), ('approval of minutes of previous sitting: see minutes', ['approval', 'of', 'minutes', 'of', 'previous', 'sitting:', 'see', 'minutes']), ('membership of parliament: see minutes', ['membership', 'of', 'parliament:', 'see', 'minutes']), ('verification of credentials: see minutes', ['verification', 'of', 'credentials:', 'see', 'minutes']), ('documents received: see minutes', ['documents', 'received:', 'see', 'minutes']), ('written statements and oral questions (tabling): see minutes', ['written', 'statements', 'and', 'oral', 'questions', '(tabling):', 'see', 'minutes']), ('petitions: see minutes', ['petitions:', 'see', 'minutes']), ('texts of agreements forwarded by the council: see minutes', ['texts', 'of', 'agreements', 'forwarded', 'by', 'the', 'council:', 'see', 'minutes']), (\"action taken on parliament's resolutions: see minutes\", ['action', 'taken', 'on', \"parliament's\", 'resolutions:', 'see', 'minutes']), ('agenda for next sitting: see minutes', ['agenda', 'for', 'next', 'sitting:', 'see', 'minutes'])]\n",
      "[('състав на парламента: вж. протоколи', ['състав', 'на', 'парламента:', 'вж.', 'протоколи']), ('одобряване на протокола от предишното заседание: вж протоколите', ['одобряване', 'на', 'протокола', 'от', 'предишното', 'заседание:', 'вж', 'протоколите']), ('състав на парламента: вж. протоколи', ['състав', 'на', 'парламента:', 'вж.', 'протоколи']), ('проверка на пълномощията: вж. протоколи', ['проверка', 'на', 'пълномощията:', 'вж.', 'протоколи']), ('внасяне на документи: вж. протоколи', ['внасяне', 'на', 'документи:', 'вж.', 'протоколи']), ('въпроси с искане за устен отговор и писмени декларации (внасяне): вж. протокола', ['въпроси', 'с', 'искане', 'за', 'устен', 'отговор', 'и', 'писмени', 'декларации', '(внасяне):', 'вж.', 'протокола']), ('петиции: вж. протоколи', ['петиции:', 'вж.', 'протоколи']), ('предаване на текстове на споразумения от съвета: вж. протоколи', ['предаване', 'на', 'текстове', 'на', 'споразумения', 'от', 'съвета:', 'вж.', 'протоколи']), ('действия, предприети вследствие резолюции на парламента: вж. протокола', ['действия,', 'предприети', 'вследствие', 'резолюции', 'на', 'парламента:', 'вж.', 'протокола']), ('дневен ред на следващото заседание: вж. протоколи', ['дневен', 'ред', 'на', 'следващото', 'заседание:', 'вж.', 'протоколи'])]\n",
      "The number of total lines for English and other langaue is 24652024,24652024 respectively.\n"
     ]
    }
   ],
   "source": [
    "#A.2.1 Pre-process the text from both RDDs by doing the following:\n",
    "#    ● Lowercase the text\n",
    "#    ● Tokenize the text (split on space)\n",
    "#    Hint: define a function to run in your driver application to avoid writing this code twice.\n",
    "#A.2.2 Inspect 10 entries from each of your RDDs to verify your pre-processing.\n",
    "    # Explaination: The requirement here is not that clear, \n",
    "    #               so a rdd with lowercase and tokenized for each line is returned.\n",
    "#A.2.3 Verify that the line counts still match after the pre-processing.\n",
    "    # Anwser: The line counts are still the same in 24652024.\n",
    "\n",
    "def prepocess(line):\n",
    "    line_lower = line.lower()\n",
    "    tokens = line_lower.split(' ')\n",
    "    return (line_lower,tokens)\n",
    "\n",
    "LoTo_E_lines = E_lines.map(prepocess)\n",
    "LoTo_O_lines = O_lines.map(prepocess)\n",
    "\n",
    "print(LoTo_E_lines.take(10))\n",
    "print(LoTo_O_lines.take(10))\n",
    "\n",
    "ToLiPr_Eng = LoTo_E_lines.map(lambda i: 1).reduce(add)\n",
    "ToLiPr_Oth = LoTo_O_lines.map(lambda i: 1).reduce(add)\n",
    "\n",
    "print(f'The number of total lines for English and other langaue is {ToLiPr_Eng},{ToLiPr_Oth} respectively.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-million",
   "metadata": {},
   "source": [
    "## Question 1.A.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "southern-mustang",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 words in English are:\n",
      "\n",
      "[('the', 46739644), ('of', 22254111), ('to', 20520872), ('and', 17433647), ('in', 14589270), ('that', 10544465), ('a', 10332226), ('is', 10077786), ('for', 7219155), ('we', 7001132)]\n",
      "\n",
      "The top 10 words in other languages are as following:\n",
      "\n",
      "bg: [('на', 604938), ('да', 330186), ('и', 328079), ('за', 261271), ('в', 228108), ('от', 168749), ('се', 150472), ('е', 129681), ('че', 114145), ('с', 95262)]\n",
      "\n",
      "cs: [('a', 484493), ('v', 292767), ('se', 214188), ('na', 200086), ('že', 189615), ('je', 189496), ('o', 128350), ('pro', 111549), ('s', 93065), ('k', 83879)]\n",
      "\n",
      "da: [('at', 1548583), ('og', 1435787), ('i', 1257318), ('er', 1029558), ('for', 931543), ('det', 921662), ('af', 908608), ('til', 752712), ('en', 677220), ('de', 663070)]\n",
      "\n",
      "de: [('die', 1980469), ('der', 1710353), ('und', 1337721), ('in', 781359), ('zu', 618872), ('den', 577654), ('wir', 489036), ('für', 478326), ('ich', 469022), ('das', 466126)]\n",
      "\n",
      "el: [('να', 1032300), ('και', 1013616), ('της', 759613), ('την', 710529), ('το', 608028), ('η', 543633), ('για', 542853), ('των', 482543), ('του', 450559), ('που', 432202)]\n",
      "\n",
      "es: [('de', 3556674), ('la', 2428991), ('que', 1823302), ('en', 1540971), ('el', 1380587), ('y', 1267385), ('a', 1140770), ('los', 1070307), ('las', 732579), ('del', 595230)]\n",
      "\n",
      "et: [('ja', 367414), ('on', 334744), ('et', 236033), ('euroopa', 140455), ('ei', 116118), ('ning', 100243), ('see', 88746), ('mis', 87777), ('kui', 79788), ('-', 69239)]\n",
      "\n",
      "fi: [('ja', 1249156), ('on', 1035956), ('että', 619655), ('euroopan', 257568), ('ei', 246268), ('myös', 178765), ('ovat', 161869), ('se', 152857), ('arvoisa', 149439), ('ole', 134745)]\n",
      "\n",
      "fr: [('de', 2908562), ('la', 1890061), ('et', 1313600), ('le', 1260986), ('les', 1147249), ('à', 1100987), ('des', 1058652), ('que', 856810), ('en', 772241), ('nous', 607262)]\n",
      "\n",
      "hu: [('a', 1045474), ('az', 510040), ('és', 402491), ('hogy', 309139), ('nem', 117436), ('európai', 110708), ('kell', 93499), ('-', 89103), ('is', 87900), ('ez', 66829)]\n",
      "\n",
      "it: [('di', 1915040), ('e', 1222655), ('che', 1129577), ('la', 1099094), ('in', 891169), ('il', 884568), ('per', 754267), ('a', 660107), ('è', 526276), ('del', 516479)]\n",
      "\n",
      "lt: [('ir', 442549), ('kad', 218805), ('europos', 120634), ('dėl', 101905), ('yra', 91141), ('-', 83274), ('su', 83247), ('į', 81427), ('tai', 73170), ('iš', 58609)]\n",
      "\n",
      "lv: [('un', 445225), ('ir', 377263), ('ka', 176276), ('par', 169978), ('es', 166357), ('eiropas', 123152), ('ar', 119663), ('kas', 109064), ('mēs', 95900), ('uz', 95407)]\n",
      "\n",
      "nl: [('de', 3846529), ('van', 2050765), ('het', 1720546), ('en', 1348857), ('in', 999524), ('een', 990694), ('dat', 985729), ('te', 726909), ('is', 622512), ('voor', 590317)]\n",
      "\n",
      "pl: [('w', 488954), ('i', 342893), ('na', 220274), ('z', 189566), ('do', 163373), ('że', 156657), ('się', 155444), ('nie', 138417), ('jest', 118263), ('to', 97921)]\n",
      "\n",
      "pt: [('de', 2370638), ('a', 2177291), ('que', 1569768), ('e', 1282952), ('o', 1240786), ('da', 835272), ('do', 718355), ('em', 648497), ('os', 581559), ('para', 553161)]\n",
      "\n",
      "ro: [('de', 454842), ('în', 342724), ('a', 221238), ('să', 205834), ('şi', 184005), ('pentru', 135231), ('la', 131109), ('care', 129987), ('și', 118273), ('că', 105950)]\n",
      "\n",
      "sk: [('a', 477378), ('v', 337162), ('na', 243380), ('sa', 232183), ('že', 183374), ('je', 176689), ('o', 132025), ('by', 106624), ('s', 100634), ('ako', 81803)]\n",
      "\n",
      "sl: [('in', 410748), ('v', 330074), ('je', 298539), ('da', 279032), ('za', 230258), ('na', 182794), ('ki', 181524), ('se', 163940), ('bi', 109828), ('so', 94703)]\n",
      "\n",
      "sv: [('att', 1706293), ('och', 1344830), ('i', 1050774), ('det', 924866), ('som', 913276), ('för', 908680), ('av', 738068), ('är', 694381), ('en', 620310), ('vi', 539797)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A.3.1 Use Spark to compute the 10 most frequently according words in the English language corpus. \n",
    "     # Repeat for the other language.\n",
    "#A.3.2 Verify that your results are reasonable.\n",
    "\n",
    "E_wordMR = E_lines\\\n",
    "          .flatMap(lambda i:i.lower().split(' '))\\\n",
    "          .map(lambda j:(j,1))\\\n",
    "          .reduceByKey(add)\\\n",
    "          .takeOrdered(10, key=lambda x: -x[1])\n",
    "print(f'The top 10 words in English are:\\n')\n",
    "print(f'{E_wordMR}\\n')\n",
    "\n",
    "print(f'The top 10 words in other languages are as following:\\n')\n",
    "for file in Other_file:\n",
    "    wordMR = spark_context.textFile(file)\\\n",
    "             .flatMap(lambda i: i.lower().split(' '))\\\n",
    "             .map(lambda j:(j,1))\\\n",
    "             .reduceByKey(add)\\\n",
    "             .takeOrdered(10, key=lambda x: -x[1])\n",
    "    print(f'{file[-2:]}: {wordMR}\\n')\n",
    "\n",
    "    \n",
    "## Another option to get the same analysis by using function.\n",
    "#N = 10;\n",
    "#def topN(file):\n",
    "#    wordMR_topN = spark_context.textFile(file)\\\n",
    "#             .flatMap(lambda i: i.lower().split(' '))\\\n",
    "#             .map(lambda j:(j,1))\\\n",
    "#             .reduceByKey(add)\\\n",
    "#             .takeOrdered(N, key=lambda x: -x[1])\n",
    "#    print(f'{file[-2:]}: {wordMR_topN }\\n')\n",
    "#\n",
    "#topN(','.join(English_file))\n",
    "#for file in Other_file:\n",
    "#    topN(file)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-tiffany",
   "metadata": {},
   "source": [
    "## Question A.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-planet",
   "metadata": {},
   "source": [
    "A.4.1 Use this parallel corpus to mine some translations in the form of word pairs, for the two languages. Do this by pairing words found on short lines with the same number of words respectively. We (incorrectly) assume the words stay in the same order when translated.\n",
    "\n",
    "Follow this approach. Work with the pair of RDDs you created in question A.2.\n",
    "Hint: make a new pair of RDDs for each step, sv_1, en_1, sv_2, en_2, ...\n",
    "\n",
    "1. Key the lines by their line number (hint: ZipWithIndex()).\n",
    "2. Swap the key and value - so that the line number is the key.\n",
    "3. Join the two RDDs together according to the line number key, so you have pairs of matching lines.\n",
    "4. Filter to exclude line pairs that have an empty/missing “corresponding” sentence.\n",
    "5. Filter to leave only pairs of sentences with a small number of words per sentence,this should give a more reliable translation (you can experiment).\n",
    "6. Filter to leave only pairs of sentences with the same number of words in each sentence.\n",
    "7. For each sentence pair, map so that you pair each (in order) word in the two sentences. We no longer need the line numbers. (hint: use python’s built in zip() function)\n",
    "8. Use reduce to count the number of occurrences of the word-translation-pairs.\n",
    "9. Print some of the most frequently occurring pairs of words.\n",
    "\n",
    "Do your translations seem reasonable? Use a dictionary to check a few (don’t worry, you won’t be marked down for incorrect translations!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incoming-simulation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en--bg top 10 matches:\n",
      "[(('is', 'е'), 1287), (('of', 'на'), 1154), (('see', 'вж'), 976), (('(applause)', '(ръкопляскания)'), 912), (('this', 'това'), 815), (('written', 'писмени'), 687), (('minutes', 'протокола'), 665), (('and', 'и'), 643), (('that', 'това'), 601), (('(rule', '(член'), 567)]\n",
      "\n",
      "en--cs top 10 matches:\n",
      "[(('(applause)', '(potlesk)'), 1749), (('is', 'je'), 1650), (('and', 'a'), 948), (('written', 'písemná'), 821), (('(rule', '(článek'), 803), (('statements', 'prohlášení'), 796), (('see', 'viz'), 725), (('minutes', 'zápis'), 719), (('that', 'to'), 660), (('thank', 'děkuji'), 617)]\n",
      "\n",
      "en--da top 10 matches:\n",
      "[(('is', 'er'), 7808), (('we', 'vi'), 3406), (('i', 'jeg'), 3041), (('that', 'det'), 2674), (('it', 'det'), 2272), (('this', 'det'), 2016), (('not', 'ikke'), 2000), (('a', 'en'), 1944), (('and', 'og'), 1916), (('(applause)', '(bifald)'), 1909)]\n",
      "\n",
      "en--de top 10 matches:\n",
      "[(('is', 'ist'), 10266), (('the', 'die'), 8644), (('debate', 'aussprache'), 4028), (('we', 'wir'), 3823), (('i', 'ich'), 3802), (('closed', 'geschlossen'), 3795), (('the', 'der'), 2702), (('that', 'das'), 2507), (('(applause)', '(beifall)'), 2303), (('and', 'und'), 2117)]\n",
      "\n",
      "en--el top 10 matches:\n",
      "[(('is', 'είναι'), 2429), (('(applause)', '(χειροκροτήματα)'), 2139), (('the', 'το'), 1272), (('this', 'αυτό'), 1191), (('the', 'η'), 1147), (('that', 'αυτό'), 1145), (('thank', 'σας'), 1058), (('and', 'και'), 931), (('mr', 'κύριε'), 782), (('you', 'ευχαριστώ'), 662)]\n",
      "\n",
      "en--es top 10 matches:\n",
      "[(('the', 'la'), 4825), (('the', 'el'), 4295), (('is', 'es'), 3399), (('of', 'de'), 2291), (('is', 'queda'), 1864), (('closed', 'cerrado'), 1792), (('debate', 'debate'), 1746), (('(applause)', '(aplausos)'), 1681), (('in', 'en'), 1302), (('vote', 'votación'), 1158)]\n",
      "\n",
      "en--et top 10 matches:\n",
      "[(('is', 'on'), 1764), (('(applause)', '(aplaus)'), 1751), (('this', 'see'), 863), (('we', 'me'), 719), (('that', 'see'), 686), (('and', 'ja'), 664), (('see', '(vt'), 603), (('minutes', 'protokoll)'), 596), (('thank', 'tänan'), 590), (('i', 'ma'), 532)]\n",
      "\n",
      "en--fi top 10 matches:\n",
      "[(('is', 'on'), 3237), (('(applause)', '(suosionosoituksia)'), 2091), (('and', 'ja'), 1104), (('this', 'tämä'), 971), (('report', 'mietintö'), 827), (('is', 'ei'), 689), (('it', 'se'), 635), (('not', 'ole'), 587), (('closed', 'päättynyt'), 569), (('debate', 'keskustelu'), 568)]\n",
      "\n",
      "en--fr top 10 matches:\n",
      "[(('the', 'le'), 7116), (('is', 'est'), 6472), (('the', 'la'), 4218), (('debate', 'débat'), 3506), (('we', 'nous'), 3467), (('closed', 'clos'), 3409), (('i', 'je'), 3083), (('of', 'de'), 2677), (('(applause)', '(applaudissements)'), 2551), (('the', 'les'), 1655)]\n",
      "\n",
      "en--hu top 10 matches:\n",
      "[(('the', 'a'), 1692), (('(applause)', '(taps)'), 1684), (('the', 'az'), 606), (('this', 'ez'), 544), (('see', 'a'), 530), (('minutes', 'jegyzőkönyvet'), 485), (('before', 'a'), 361), (('and', 'és'), 349), (('this', 'a'), 324), (('not', 'nem'), 322)]\n",
      "\n",
      "en--it top 10 matches:\n",
      "[(('is', 'è'), 5262), (('the', 'la'), 5031), (('closed', 'chiusa'), 2879), (('debate', 'discussione'), 2763), (('(applause)', '(applausi)'), 1959), (('the', 'il'), 1430), (('of', 'di'), 951), (('and', 'e'), 743), (('this', 'questo'), 730), (('a', 'un'), 652)]\n",
      "\n",
      "en--lt top 10 matches:\n",
      "[(('(applause)', '(plojimai)'), 1675), (('and', 'ir'), 644), (('is', 'yra'), 428), (('this', 'tai'), 385), (('we', 'mes'), 364), (('of', 'dėl'), 349), (('explanations', 'paaiškinimai'), 339), (('vote', 'balsavimo'), 337), (('see', '(žr'), 337), (('minutes', 'protokolą)'), 320)]\n",
      "\n",
      "en--lv top 10 matches:\n",
      "[(('is', 'ir'), 1789), (('(applause)', '(aplausi)'), 1726), (('i', 'es'), 1169), (('and', 'un'), 896), (('we', 'mēs'), 830), (('we', 'mums'), 597), (('this', 'tas'), 533), (('are', 'ir'), 472), (('that', 'tas'), 471), (('minutes', 'protokolu)'), 418)]\n",
      "\n",
      "en--nl top 10 matches:\n",
      "[(('is', 'is'), 10319), (('the', 'de'), 7813), (('the', 'het'), 5908), (('debate', 'debat'), 3647), (('closed', 'gesloten'), 3584), (('of', 'van'), 3023), (('that', 'dat'), 2948), (('i', 'ik'), 2914), (('a', 'een'), 2620), (('(applause)', '(applaus)'), 2282)]\n",
      "\n",
      "en--pl top 10 matches:\n",
      "[(('(applause)', '(oklaski)'), 1656), (('is', 'jest'), 829), (('see', 'patrz'), 815), (('minutes', 'protokół'), 794), (('and', 'i'), 785), (('in', 'w'), 578), (('is', 'to'), 407), (('to', 'do'), 390), (('this', 'to'), 320), (('(', '('), 294)]\n",
      "\n",
      "en--pt top 10 matches:\n",
      "[(('is', 'o'), 3218), (('the', 'está'), 3217), (('closed', 'debate'), 2880), (('debate', 'encerrado'), 2863), (('is', 'é'), 2724), (('the', 'a'), 2707), (('the', 'o'), 2459), (('(applause)', '(aplausos)'), 1592), (('of', 'de'), 1197), (('a', 'um'), 902)]\n",
      "\n",
      "en--ro top 10 matches:\n",
      "[(('is', 'este'), 1152), (('(applause)', '(aplauze)'), 893), (('thank', 'vă'), 681), (('closed', 'închisă'), 523), (('is', 'fost'), 519), (('the', 'dezbaterea'), 518), (('debate', 'a'), 514), (('in', 'în'), 485), (('a', 'o'), 476), (('for', 'pentru'), 402)]\n",
      "\n",
      "en--sk top 10 matches:\n",
      "[(('(applause)', '(potlesk)'), 1724), (('is', 'je'), 1656), (('written', 'písomné'), 946), (('(rule', '(článok'), 885), (('statements', 'vyhlásenia'), 856), (('see', 'pozri'), 794), (('and', 'a'), 793), (('minutes', 'zápisnicu'), 793), (('that', 'to'), 622), (('is', 'to'), 489)]\n",
      "\n",
      "en--sl top 10 matches:\n",
      "[(('is', 'je'), 2098), (('(applause)', '(aplavz)'), 1083), (('this', 'to'), 1052), (('and', 'in'), 852), (('(rule', '(člen'), 850), (('written', 'pisne'), 845), (('statements', 'izjave'), 765), (('that', 'to'), 741), (('minutes', 'zapisnik'), 721), (('see', 'glej'), 602)]\n",
      "\n",
      "en--sv top 10 matches:\n",
      "[(('is', 'är'), 10068), (('we', 'vi'), 5534), (('i', 'jag'), 5029), (('this', 'detta'), 3727), (('that', 'det'), 3109), (('it', 'det'), 3073), (('closed', 'avslutad'), 2971), (('and', 'och'), 2920), (('a', 'en'), 2893), (('not', 'inte'), 2719)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def kv_rev(rdd):\n",
    "    nrdd = rdd.zipWithIndex()\\\n",
    "              .map(lambda line:(line[1],line[0]))\n",
    "    return nrdd\n",
    "\n",
    "j = len(Other_file) \n",
    "\n",
    "# The reason to choose for loop here is when change the input of range(), different bunches of files are able to\n",
    "# be analyzed, and that will lower down the excutue core numbers and process time.\n",
    "# and when the above j is the input, all the files then will be analyzed.\n",
    "\n",
    "for i in range(j):\n",
    "    e = spark_context.textFile(English_file[i]) \n",
    "    o = spark_context.textFile(Other_file[i])  \n",
    "    pairedrdd = kv_rev(e).join(kv_rev(o))\n",
    "    #print(f'{pairedrdd.take(10)}\\n')\n",
    "    \n",
    "    n = 10 # This number is used to filter the lines with n words\n",
    "    npairedrdd = pairedrdd.filter(lambda i: bool((i[1][0].strip()) and (i[1][1].strip())))\\\n",
    "            .filter(lambda i: bool((len(i[1][0].strip().split(' '))<n) and (len(i[1][1].strip().split(' '))<n)))\\\n",
    "            .filter(lambda i: bool(len(i[1][0].strip().split(' '))==len(i[1][1].strip().split(' '))))\n",
    "    #print(f'After filter:{npairedrdd.take(10)}\\n')\n",
    "\n",
    "    num = 10 # This number is used for picking out the top num pairs.\n",
    "    wordpair = npairedrdd.flatMap(lambda i: i[1][0].strip().lower().split(' '))\\\n",
    "                .zip(npairedrdd.flatMap(lambda i: i[1][1].strip().lower().split(' ')))\\\n",
    "                .map(lambda i: (i[0].replace('.',''),i[1].replace('.','')))\\\n",
    "                .map(lambda i: (i[0].replace('-',''),i[1].replace('-','')))\\\n",
    "                .filter(lambda i: bool(not(i[0].isnumeric() or i[1].isnumeric())))\\\n",
    "                .filter(lambda i: bool(i[0] and i[1]))\\\n",
    "                .map(lambda i:(i,1))\\\n",
    "                .reduceByKey(add)\\\n",
    "                .takeOrdered(num, key=lambda x: -x[1])\n",
    "    print(f'en--{Other_file[i][-2:]} top {num} matches:\\n{wordpair}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "superb-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-extraction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
